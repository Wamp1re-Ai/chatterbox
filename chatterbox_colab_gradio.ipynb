{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸ™ï¸ ChatterBox TTS - Gradio UI Demo (Google Colab)\n",
    "\n",
    "[\\![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/chatterbox/blob/master/chatterbox_colab_gradio.ipynb)\n",
    "\n",
    "Welcome to the **ChatterBox TTS Gradio Interface** on Google Colab\\! This notebook demonstrates how to run the enhanced Gradio UI with public URL sharing.\n",
    "\n",
    "## ğŸŒŸ What You'll Get\n",
    "- **ğŸŒ Live Gradio Interface**: Professional web UI with public URL\n",
    "- **ğŸ¤ Text-to-Speech**: Generate speech from any text\n",
    "- **ğŸ­ Voice Cloning**: Clone voices using audio samples\n",
    "- **ğŸ”— Public URL**: Share the interface with anyone worldwide\n",
    "- **ğŸ›ï¸ Advanced Controls**: Emotion, stability, and variation settings\n",
    "- **ğŸš€ GPU Acceleration**: Fast generation with Colab's free GPU\n",
    "\n",
    "## ğŸš€ Quick Start\n",
    "1. **Enable GPU**: Runtime â†’ Change runtime type â†’ GPU\n",
    "2. **Run all cells**: Runtime â†’ Run all (Ctrl+F9)\n",
    "3. **Wait for launch**: Look for the public URL in the output\n",
    "4. **Share & Test**: Use the URL to access from anywhere\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## âš™ï¸ Setup & Installation\n",
    "\n",
    "First, let's check the environment and install all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_environment"
   },
   "outputs": [],
   "source": [
    "# Check environment and GPU availability\n",
    "import torch\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ” Environment Check\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ”¥ PyTorch: {torch.__version__}\")\n",
    "print(f\"ğŸ–¥ï¸ CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸš€ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"ğŸ’» Using CPU (consider enabling GPU in Runtime settings)\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"\nğŸ¯ Selected Device: {device}\")\n",
    "print()\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"âœ… Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"â„¹ï¸ Not running in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install ChatterBox TTS and Gradio\n",
    "print(\"ğŸ“¦ Installing Dependencies\")\n",
    "print(\"=\" * 40)\n",
    "print(\"â³ This may take 3-5 minutes...\")\n",
    "print()\n",
    "\n",
    "# Install packages with progress\n",
    "packages = [\n",
    "    \"gradio>=4.0.0\",\n",
    "    \"chatterbox-tts\",\n",
    "    \"librosa>=0.9.0\"\n",
    "]\n",
    "\n",
    "for i, package in enumerate(packages, 1):\n",
    "    print(f\"ğŸ“¥ [{i}/{len(packages)}] Installing {package}...\")\n",
    "    try:\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"\n",
    "        ], check=True, capture_output=True, text=True)\n",
    "        print(f\"âœ… {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Failed to install {package}\")\n",
    "        print(f\"Error: {e.stderr}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ‰ Installation complete\\!\")\n",
    "print(\"ğŸ”„ Restarting runtime to load new packages...\")\n",
    "\n",
    "# Restart runtime in Colab to ensure packages are loaded\n",
    "if IN_COLAB:\n",
    "    print(\"âš ï¸ Runtime will restart automatically. Please run the next cell after restart.\")\n",
    "    os.kill(os.getpid(), 9)  # Force restart in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "post_restart"
   },
   "source": [
    "## ğŸ”„ After Runtime Restart\n",
    "\n",
    "**Run this cell after the runtime restarts** to load the installed packages and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_packages"
   },
   "outputs": [],
   "source": [
    "# Load packages after restart\n",
    "import gradio as gr\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_TEXT_LENGTH = 500\n",
    "model = None\n",
    "\n",
    "print(\"ğŸ“¦ Packages loaded successfully\\!\")\n",
    "print(f\"ğŸ¯ Device: {DEVICE}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸš€ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"ğŸ’» Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load ChatterBox TTS model\n",
    "def load_chatterbox_model():\n",
    "    \"\"\"Load ChatterBox TTS model\"\"\"\n",
    "    global model\n",
    "    \n",
    "    if model is not None:\n",
    "        return model, \"âœ… Model already loaded\"\n",
    "    \n",
    "    try:\n",
    "        from chatterbox.tts import ChatterboxTTS\n",
    "        \n",
    "        print(\"ğŸ“¥ Loading ChatterBox TTS model...\")\n",
    "        print(\"â³ First run: downloading ~2GB model weights...\")\n",
    "        print(\"ğŸš€ Using GPU acceleration for faster loading\\!\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model = ChatterboxTTS.from_pretrained(device=DEVICE)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        status = f\"âœ… Model loaded in {load_time:.1f}s\\n\"\n",
    "        status += f\"ğŸµ Sample rate: {model.sr} Hz\\n\"\n",
    "        status += f\"ğŸ¯ Device: {model.device}\"\n",
    "        \n",
    "        print(status)\n",
    "        return model, status\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ Model loading failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return None, error_msg\n",
    "\n",
    "# Load the model\n",
    "print(\"ğŸ¤– Loading ChatterBox TTS Model\")\n",
    "print(\"=\" * 40)\n",
    "model, status = load_chatterbox_model()\n",
    "print(\"\n\" + \"=\" * 40)\n",
    "if model:\n",
    "    print(\"ğŸ‰ Ready to generate speech\\!\")\n",
    "else:\n",
    "    print(\"âŒ Model loading failed. Check the error above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_functions"
   },
   "source": [
    "## ğŸ›ï¸ Gradio Interface Functions\n",
    "\n",
    "Define the core functions for the Gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tts_functions"
   },
   "outputs": [],
   "source": [
    "# TTS generation and helper functions\n",
    "def generate_speech(text, reference_audio, exaggeration, cfg_weight, temperature, seed, preset):\n",
    "    \"\"\"Generate TTS audio\"\"\"\n",
    "    \n",
    "    if not text or not text.strip():\n",
    "        return None, \"âŒ Please enter some text to synthesize\"\n",
    "    \n",
    "    if len(text) > MAX_TEXT_LENGTH:\n",
    "        return None, f\"âŒ Text too long. Maximum {MAX_TEXT_LENGTH} characters.\"\n",
    "    \n",
    "    if model is None:\n",
    "        return None, \"âŒ Model not loaded. Please run the model loading cell.\"\n",
    "    \n",
    "    try:\n",
    "        # Apply preset if selected\n",
    "        if preset \\!= \"Custom\":\n",
    "            preset_configs = get_preset_configs()\n",
    "            if preset in preset_configs:\n",
    "                config = preset_configs[preset]\n",
    "                exaggeration = config[\"exaggeration\"]\n",
    "                cfg_weight = config[\"cfg_weight\"]\n",
    "                temperature = config[\"temperature\"]\n",
    "        \n",
    "        # Set seed\n",
    "        if seed == 0:\n",
    "            seed = random.randint(1, 1000000)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        # Generate\n",
    "        start_time = time.time()\n",
    "        \n",
    "        params = {\n",
    "            \"exaggeration\": exaggeration,\n",
    "            \"cfg_weight\": cfg_weight,\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "        \n",
    "        if reference_audio:\n",
    "            params[\"audio_prompt_path\"] = reference_audio\n",
    "        \n",
    "        wav = model.generate(text, **params)\n",
    "        generation_time = time.time() - start_time\n",
    "        \n",
    "        # Convert to numpy\n",
    "        audio_np = wav.squeeze(0).numpy()\n",
    "        duration = len(audio_np) / model.sr\n",
    "        rtf = generation_time / duration\n",
    "        \n",
    "        status = f\"âœ… Generated {duration:.1f}s audio in {generation_time:.1f}s\\n\"\n",
    "        status += f\"ğŸ“Š RTF: {rtf:.2f}x | Seed: {seed}\\n\"\n",
    "        status += f\"ğŸ›ï¸ exag={exaggeration:.1f}, cfg={cfg_weight:.1f}, temp={temperature:.1f}\"\n",
    "        \n",
    "        return (model.sr, audio_np), status\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"âŒ Generation failed: {str(e)}\"\n",
    "\n",
    "def get_preset_configs():\n",
    "    \"\"\"Preset configurations\"\"\"\n",
    "    return {\n",
    "        \"Neutral\": {\"exaggeration\": 0.5, \"cfg_weight\": 0.5, \"temperature\": 0.8},\n",
    "        \"Calm & Controlled\": {\"exaggeration\": 0.2, \"cfg_weight\": 0.7, \"temperature\": 0.6},\n",
    "        \"Expressive & Dynamic\": {\"exaggeration\": 0.8, \"cfg_weight\": 0.3, \"temperature\": 0.9},\n",
    "        \"Dramatic & Intense\": {\"exaggeration\": 1.2, \"cfg_weight\": 0.2, \"temperature\": 1.0},\n",
    "        \"Robotic & Stable\": {\"exaggeration\": 0.1, \"cfg_weight\": 0.8, \"temperature\": 0.5},\n",
    "        \"Creative & Varied\": {\"exaggeration\": 0.7, \"cfg_weight\": 0.4, \"temperature\": 1.2}\n",
    "    }\n",
    "\n",
    "def apply_preset(preset):\n",
    "    \"\"\"Apply preset configuration\"\"\"\n",
    "    if preset == \"Custom\":\n",
    "        return 0.5, 0.5, 0.8\n",
    "    configs = get_preset_configs()\n",
    "    if preset in configs:\n",
    "        config = configs[preset]\n",
    "        return config[\"exaggeration\"], config[\"cfg_weight\"], config[\"temperature\"]\n",
    "    return 0.5, 0.5, 0.8\n",
    "\n",
    "# Sample texts\n",
    "SAMPLE_TEXTS = [\n",
    "    \"Hello\\! Welcome to ChatterBox TTS, running on Google Colab with GPU acceleration\\!\",\n",
    "    \"The quick brown fox jumps over the lazy dog. This pangram contains every letter.\",\n",
    "    \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole.\",\n",
    "    \"To be or not to be, that is the question. Whether 'tis nobler in the mind.\",\n",
    "    \"It was the best of times, it was the worst of times, it was the age of wisdom.\",\n",
    "    \"Space: the final frontier. These are the voyages of the starship Enterprise.\"\n",
    "]\n",
    "\n",
    "def load_sample_text(sample_choice):\n",
    "    \"\"\"Load sample text\"\"\"\n",
    "    if sample_choice == \"Custom\":\n",
    "        return \"\"\n",
    "    try:\n",
    "        index = int(sample_choice.split(\".\")[0]) - 1\n",
    "        if 0 <= index < len(SAMPLE_TEXTS):\n",
    "            return SAMPLE_TEXTS[index]\n",
    "    except:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "print(\"âœ… TTS functions loaded\\!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_interface"
   },
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "def create_gradio_interface():\n",
    "    \"\"\"Create the Gradio interface\"\"\"\n",
    "    \n",
    "    css = \"\"\"\n",
    "    .gradio-container { max-width: 1200px \\!important; }\n",
    "    .header-text { text-align: center; color: #2d5aa0; margin-bottom: 20px; }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=css, title=\"ChatterBox TTS - Colab\") as demo:\n",
    "        \n",
    "        gr.HTML(\"\"\"\n",
    "        <div class=\"header-text\">\n",
    "            <h1>ğŸ™ï¸ ChatterBox TTS Studio</h1>\n",
    "            <p>ğŸš€ <strong>Google Colab Edition</strong> with GPU Acceleration</p>\n",
    "            <p>State-of-the-art Text-to-Speech â€¢ Voice Cloning â€¢ Public URL Sharing</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                gr.Markdown(\"### ğŸ“ Text Input\")\n",
    "                \n",
    "                sample_dropdown = gr.Dropdown(\n",
    "                    choices=[\"Custom\"] + [f\"{i+1}. {text[:50]}...\" for i, text in enumerate(SAMPLE_TEXTS)],\n",
    "                    value=\"Custom\",\n",
    "                    label=\"Quick Sample Texts\"\n",
    "                )\n",
    "                \n",
    "                text_input = gr.Textbox(\n",
    "                    value=\"Hello\\! Welcome to ChatterBox TTS, running on Google Colab with GPU acceleration\\!\",\n",
    "                    label=f\"Text to Synthesize (Max {MAX_TEXT_LENGTH} chars)\",\n",
    "                    placeholder=\"Enter your text here...\",\n",
    "                    lines=4\n",
    "                )\n",
    "                \n",
    "                reference_audio = gr.Audio(\n",
    "                    sources=[\"upload\", \"microphone\"],\n",
    "                    type=\"filepath\",\n",
    "                    label=\"Reference Audio (Optional) - For voice cloning\"\n",
    "                )\n",
    "                \n",
    "                gr.Markdown(\"### ğŸ›ï¸ Generation Settings\")\n",
    "                \n",
    "                preset_dropdown = gr.Dropdown(\n",
    "                    choices=[\"Custom\"] + list(get_preset_configs().keys()),\n",
    "                    value=\"Neutral\",\n",
    "                    label=\"Preset Configurations\"\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    exaggeration_slider = gr.Slider(\n",
    "                        0.0, 2.0, step=0.1, value=0.5,\n",
    "                        label=\"Exaggeration (Emotion)\"\n",
    "                    )\n",
    "                    cfg_weight_slider = gr.Slider(\n",
    "                        0.0, 1.0, step=0.05, value=0.5,\n",
    "                        label=\"CFG Weight (Control)\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    temperature_slider = gr.Slider(\n",
    "                        0.1, 2.0, step=0.1, value=0.8,\n",
    "                        label=\"Temperature (Variation)\"\n",
    "                    )\n",
    "                    seed_input = gr.Number(\n",
    "                        value=0,\n",
    "                        label=\"Seed (0=random)\"\n",
    "                    )\n",
    "                \n",
    "                generate_btn = gr.Button(\n",
    "                    \"ğŸµ Generate Speech\",\n",
    "                    variant=\"primary\",\n",
    "                    size=\"lg\"\n",
    "                )\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"### ğŸ”Š Generated Audio\")\n",
    "                \n",
    "                audio_output = gr.Audio(\n",
    "                    label=\"Generated Speech\",\n",
    "                    show_download_button=True\n",
    "                )\n",
    "                \n",
    "                status_output = gr.Textbox(\n",
    "                    label=\"Generation Status\",\n",
    "                    lines=8,\n",
    "                    interactive=False\n",
    "                )\n",
    "                \n",
    "                gr.Markdown(\"### âš¡ Quick Actions\")\n",
    "                with gr.Row():\n",
    "                    clear_btn = gr.Button(\"ğŸ—‘ï¸ Clear\", size=\"sm\")\n",
    "                    info_btn = gr.Button(\"â„¹ï¸ Info\", size=\"sm\")\n",
    "        \n",
    "        # Event handlers\n",
    "        sample_dropdown.change(load_sample_text, [sample_dropdown], [text_input])\n",
    "        preset_dropdown.change(apply_preset, [preset_dropdown], [exaggeration_slider, cfg_weight_slider, temperature_slider])\n",
    "        generate_btn.click(generate_speech, [text_input, reference_audio, exaggeration_slider, cfg_weight_slider, temperature_slider, seed_input, preset_dropdown], [audio_output, status_output])\n",
    "        clear_btn.click(lambda: (None, \"\"), [], [audio_output, status_output])\n",
    "        \n",
    "        def show_info():\n",
    "            info = f\"ğŸ™ï¸ ChatterBox TTS - Colab Edition\\n\\n\"\n",
    "            info += f\"ğŸ–¥ï¸ Device: {DEVICE}\\n\"\n",
    "            if model:\n",
    "                info += f\"ğŸµ Sample Rate: {model.sr} Hz\\n\"\n",
    "                info += f\"ğŸ¯ Model Device: {model.device}\\n\"\n",
    "            info += \"\\nğŸ“Š Available Presets:\\n\"\n",
    "            for name, config in get_preset_configs().items():\n",
    "                info += f\"â€¢ {name}: exag={config['exaggeration']}, cfg={config['cfg_weight']}, temp={config['temperature']}\\n\"\n",
    "            return info\n",
    "        \n",
    "        info_btn.click(show_info, [], [status_output])\n",
    "    \n",
    "    return demo\n",
    "\n",
    "print(\"âœ… Gradio interface ready\\!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "launch_interface"
   },
   "source": [
    "## ğŸš€ Launch Gradio Interface with Public URL\n",
    "\n",
    "**ğŸ¯ This is the main cell\\!** Run this to launch the Gradio interface with a public URL.\n",
    "\n",
    "### ğŸŒ Public URL Benefits\n",
    "- **Share instantly**: Send the URL to anyone\n",
    "- **No installation**: Works on any device with a browser\n",
    "- **Collaborative**: Multiple people can use it simultaneously\n",
    "- **Secure**: HTTPS encryption and temporary URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_gradio"
   },
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "if model is not None:\n",
    "    print(\"ğŸš€ Launching ChatterBox TTS Gradio Interface...\")\n",
    "    print(\"ğŸ“¡ Creating public URL for worldwide access...\")\n",
    "    print(\"â³ This may take a moment...\")\n",
    "    print()\n",
    "    \n",
    "    # Create and launch the interface\n",
    "    demo = create_gradio_interface()\n",
    "    \n",
    "    # Launch with public URL sharing\n",
    "    demo.launch(\n",
    "        share=True,           # ğŸŒ Enable public URL sharing\n",
    "        debug=False,          # Disable debug mode for cleaner output\n",
    "        show_error=True,      # Show detailed error messages\n",
    "        server_name=\"0.0.0.0\",   # Allow external connections\n",
    "        server_port=7860,     # Default port\n",
    "        enable_queue=True,    # Enable request queuing\n",
    "        max_threads=4,        # Limit concurrent requests\n",
    "        show_tips=True,       # Show helpful tips\n",
    "        quiet=False           # Show launch information\n",
    "    )\n",
    "else:\n",
    "    print(\"âŒ Cannot launch interface - model not loaded\\!\")\n",
    "    print(\"ğŸ’¡ Please run the model loading cell above first.\")\n",
    "    print(\"ğŸ”„ If the model failed to load, try restarting the runtime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "success_info"
   },
   "source": [
    "## ğŸ‰ Success\\! Interface Launched\n",
    "\n",
    "If everything worked correctly, you should see output above with:\n",
    "\n",
    "### ğŸ”— URLs Generated\n",
    "1. **Local URL**:  (Colab internal)\n",
    "2. **ğŸŒ Public URL**:  â† **Share this one\\!**\n",
    "\n",
    "### ğŸ“¤ How to Share & Test\n",
    "\n",
    "1. **ğŸ“‹ Copy the public URL** from the output above\n",
    "2. **ğŸ”— Share it with anyone** - they can access immediately\n",
    "3. **ğŸ“± Test on different devices** - phones, tablets, computers\n",
    "4. **ğŸ‘¥ Collaborate in real-time** - multiple users can use it\n",
    "\n",
    "### ğŸ¯ Interface Features\n",
    "\n",
    "- **ğŸ¤ Text-to-Speech**: Type any text and generate natural speech\n",
    "- **ğŸ­ Voice Cloning**: Upload audio samples to clone voices\n",
    "- **ğŸ›ï¸ Advanced Controls**: Fine-tune emotion, stability, and variation\n",
    "- **ğŸ² Presets**: Quick settings for different speech styles\n",
    "- **ğŸ“ Sample Texts**: Built-in examples for immediate testing\n",
    "- **ğŸ”Š Audio Playback**: Listen and download generated speech\n",
    "- **ğŸš€ GPU Acceleration**: Fast generation with Colab's GPU\n",
    "\n",
    "### ğŸ’¡ Pro Tips\n",
    "\n",
    "- **ğŸ¯ Best Results**: Use clear, punctuated text (avoid very long sentences)\n",
    "- **ğŸ¤ Voice Cloning**: Upload 3-10 seconds of clear, single-speaker audio\n",
    "- **ğŸ›ï¸ Parameters**: Start with presets, then fine-tune manually\n",
    "- **â° URL Expiry**: Public URLs expire after 72 hours for security\n",
    "- **ğŸ”„ Keep Running**: Keep this Colab tab open while others use the URL\n",
    "\n",
    "### ğŸ› Troubleshooting\n",
    "\n",
    "- **No URL generated**: Check if the model loaded successfully above\n",
    "- **Interface not responding**: Restart runtime and run all cells again\n",
    "- **Slow generation**: Normal on CPU, much faster with GPU enabled\n",
    "- **Audio issues**: Check browser permissions and audio settings\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ™ï¸ Enjoy creating amazing voices with ChatterBox TTS\\!**\n",
    "\n",
    "**ğŸ”— Share the public URL** and let others experience the power of AI voice synthesis\\!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}