{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéôÔ∏è ChatterBox TTS - Gradio UI Demo (Google Colab)\n",
    "\n",
    "[\\![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/chatterbox/blob/master/chatterbox_colab_gradio.ipynb)\n",
    "\n",
    "Welcome to the **ChatterBox TTS Gradio Interface** on Google Colab\\! This notebook demonstrates how to run the enhanced Gradio UI with public URL sharing.\n",
    "\n",
    "## üåü What You'll Get\n",
    "- **üåê Live Gradio Interface**: Professional web UI with public URL\n",
    "- **üé§ Text-to-Speech**: Generate speech from any text\n",
    "- **üé≠ Voice Cloning**: Clone voices using audio samples\n",
    "- **üîó Public URL**: Share the interface with anyone worldwide\n",
    "- **üéõÔ∏è Advanced Controls**: Emotion, stability, and variation settings\n",
    "- **üöÄ GPU Acceleration**: Fast generation with Colab's free GPU\n",
    "\n",
    "## üöÄ Quick Start\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. **Run all cells**: Runtime ‚Üí Run all (Ctrl+F9)\n",
    "3. **Wait for launch**: Look for the public URL in the output\n",
    "4. **Share & Test**: Use the URL to access from anywhere\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ‚öôÔ∏è Setup & Installation\n",
    "\n",
    "First, let's check the environment and install all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_environment"
   },
   "outputs": [],
   "source": [
    "# Check environment and GPU availability\n",
    "import torch\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üîç Environment Check\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "print(f\"üñ•Ô∏è CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"üíª Using CPU (consider enabling GPU in Runtime settings)\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"\nüéØ Selected Device: {device}\")\n",
    "print()\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚ÑπÔ∏è Not running in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install ChatterBox TTS and Gradio\n",
    "print(\"üì¶ Installing Dependencies\")\n",
    "print(\"=\" * 40)\n",
    "print(\"‚è≥ This may take 3-5 minutes...\")\n",
    "print()\n",
    "\n",
    "# Install packages with progress\n",
    "packages = [\n",
    "    \"gradio>=4.0.0\",\n",
    "    \"chatterbox-tts\",\n",
    "    \"librosa>=0.9.0\"\n",
    "]\n",
    "\n",
    "for i, package in enumerate(packages, 1):\n",
    "    print(f\"üì• [{i}/{len(packages)}] Installing {package}...\")\n",
    "    try:\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"\n",
    "        ], check=True, capture_output=True, text=True)\n",
    "        print(f\"‚úÖ {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to install {package}\")\n",
    "        print(f\"Error: {e.stderr}\")\n",
    "\n",
    "print()\n",
    "print(\"üéâ Installation complete\\!\")\n",
    "print(\"üîÑ Restarting runtime to load new packages...\")\n",
    "\n",
    "# Restart runtime in Colab to ensure packages are loaded\n",
    "if IN_COLAB:\n",
    "    print(\"‚ö†Ô∏è Runtime will restart automatically. Please run the next cell after restart.\")\n",
    "    os.kill(os.getpid(), 9)  # Force restart in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "post_restart"
   },
   "source": [
    "## üîÑ After Runtime Restart\n",
    "\n",
    "**Run this cell after the runtime restarts** to load the installed packages and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_packages"
   },
   "outputs": [],
   "source": [
    "# Load packages after restart\n",
    "import gradio as gr\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_TEXT_LENGTH = 500\n",
    "model = None\n",
    "\n",
    "print(\"üì¶ Packages loaded successfully\\!\")\n",
    "print(f\"üéØ Device: {DEVICE}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"üíª Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load ChatterBox TTS model\n",
    "def load_chatterbox_model():\n",
    "    \"\"\"Load ChatterBox TTS model\"\"\"\n",
    "    global model\n",
    "    \n",
    "    if model is not None:\n",
    "        return model, \"‚úÖ Model already loaded\"\n",
    "    \n",
    "    try:\n",
    "        from chatterbox.tts import ChatterboxTTS\n",
    "        \n",
    "        print(\"üì• Loading ChatterBox TTS model...\")\n",
    "        print(\"‚è≥ First run: downloading ~2GB model weights...\")\n",
    "        print(\"üöÄ Using GPU acceleration for faster loading\\!\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model = ChatterboxTTS.from_pretrained(device=DEVICE)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        status = f\"‚úÖ Model loaded in {load_time:.1f}s\\n\"\n",
    "        status += f\"üéµ Sample rate: {model.sr} Hz\\n\"\n",
    "        status += f\"üéØ Device: {model.device}\"\n",
    "        \n",
    "        print(status)\n",
    "        return model, status\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Model loading failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return None, error_msg\n",
    "\n",
    "# Load the model\n",
    "print(\"ü§ñ Loading ChatterBox TTS Model\")\n",
    "print(\"=\" * 40)\n",
    "model, status = load_chatterbox_model()\n",
    "print(\"\n\" + \"=\" * 40)\n",
    "if model:\n",
    "    print(\"üéâ Ready to generate speech\\!\")\n",
    "else:\n",
    "    print(\"‚ùå Model loading failed. Check the error above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_functions"
   },
   "source": [
    "## üéõÔ∏è Gradio Interface Functions\n",
    "\n",
    "Define the core functions for the Gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tts_functions"
   },
   "outputs": [],
   "source": [
    "# TTS generation and helper functions\n",
    "def generate_speech(text, reference_audio, exaggeration, cfg_weight, temperature, seed, preset):\n",
    "    \"\"\"Generate TTS audio\"\"\"\n",
    "    \n",
    "    if not text or not text.strip():\n",
    "        return None, \"‚ùå Please enter some text to synthesize\"\n",
    "    \n",
    "    if len(text) > MAX_TEXT_LENGTH:\n",
    "        return None, f\"‚ùå Text too long. Maximum {MAX_TEXT_LENGTH} characters.\"\n",
    "    \n",
    "    if model is None:\n",
    "        return None, \"‚ùå Model not loaded. Please run the model loading cell.\"\n",
    "    \n",
    "    try:\n",
    "        # Apply preset if selected\n",
    "        if preset \\!= \"Custom\":\n",
    "            preset_configs = get_preset_configs()\n",
    "            if preset in preset_configs:\n",
    "                config = preset_configs[preset]\n",
    "                exaggeration = config[\"exaggeration\"]\n",
    "                cfg_weight = config[\"cfg_weight\"]\n",
    "                temperature = config[\"temperature\"]\n",
    "        \n",
    "        # Set seed\n",
    "        if seed == 0:\n",
    "            seed = random.randint(1, 1000000)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        # Generate\n",
    "        start_time = time.time()\n",
    "        \n",
    "        params = {\n",
    "            \"exaggeration\": exaggeration,\n",
    "            \"cfg_weight\": cfg_weight,\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "        \n",
    "        if reference_audio:\n",
    "            params[\"audio_prompt_path\"] = reference_audio\n",
    "        \n",
    "        wav = model.generate(text, **params)\n",
    "        generation_time = time.time() - start_time\n",
    "        \n",
    "        # Convert to numpy\n",
    "        audio_np = wav.squeeze(0).numpy()\n",
    "        duration = len(audio_np) / model.sr\n",
    "        rtf = generation_time / duration\n",
    "        \n",
    "        status = f\"‚úÖ Generated {duration:.1f}s audio in {generation_time:.1f}s\\n\"\n",
    "        status += f\"üìä RTF: {rtf:.2f}x | Seed: {seed}\\n\"\n",
    "        status += f\"üéõÔ∏è exag={exaggeration:.1f}, cfg={cfg_weight:.1f}, temp={temperature:.1f}\"\n",
    "        \n",
    "        return (model.sr, audio_np), status\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"‚ùå Generation failed: {str(e)}\"\n",
    "\n",
    "def get_preset_configs():\n",
    "    \"\"\"Preset configurations\"\"\"\n",
    "    return {\n",
    "        \"Neutral\": {\"exaggeration\": 0.5, \"cfg_weight\": 0.5, \"temperature\": 0.8},\n",
    "        \"Calm & Controlled\": {\"exaggeration\": 0.2, \"cfg_weight\": 0.7, \"temperature\": 0.6},\n",
    "        \"Expressive & Dynamic\": {\"exaggeration\": 0.8, \"cfg_weight\": 0.3, \"temperature\": 0.9},\n",
    "        \"Dramatic & Intense\": {\"exaggeration\": 1.2, \"cfg_weight\": 0.2, \"temperature\": 1.0},\n",
    "        \"Robotic & Stable\": {\"exaggeration\": 0.1, \"cfg_weight\": 0.8, \"temperature\": 0.5},\n",
    "        \"Creative & Varied\": {\"exaggeration\": 0.7, \"cfg_weight\": 0.4, \"temperature\": 1.2}\n",
    "    }\n",
    "\n",
    "def apply_preset(preset):\n",
    "    \"\"\"Apply preset configuration\"\"\"\n",
    "    if preset == \"Custom\":\n",
    "        return 0.5, 0.5, 0.8\n",
    "    configs = get_preset_configs()\n",
    "    if preset in configs:\n",
    "        config = configs[preset]\n",
    "        return config[\"exaggeration\"], config[\"cfg_weight\"], config[\"temperature\"]\n",
    "    return 0.5, 0.5, 0.8\n",
    "\n",
    "# Sample texts\n",
    "SAMPLE_TEXTS = [\n",
    "    \"Hello\\! Welcome to ChatterBox TTS, running on Google Colab with GPU acceleration\\!\",\n",
    "    \"The quick brown fox jumps over the lazy dog. This pangram contains every letter.\",\n",
    "    \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole.\",\n",
    "    \"To be or not to be, that is the question. Whether 'tis nobler in the mind.\",\n",
    "    \"It was the best of times, it was the worst of times, it was the age of wisdom.\",\n",
    "    \"Space: the final frontier. These are the voyages of the starship Enterprise.\"\n",
    "]\n",
    "\n",
    "def load_sample_text(sample_choice):\n",
    "    \"\"\"Load sample text\"\"\"\n",
    "    if sample_choice == \"Custom\":\n",
    "        return \"\"\n",
    "    try:\n",
    "        index = int(sample_choice.split(\".\")[0]) - 1\n",
    "        if 0 <= index < len(SAMPLE_TEXTS):\n",
    "            return SAMPLE_TEXTS[index]\n",
    "    except:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "print(\"‚úÖ TTS functions loaded\\!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_interface"
   },
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "def create_gradio_interface():\n",
    "    \"\"\"Create the Gradio interface\"\"\"\n",
    "    \n",
    "    css = \"\"\"\n",
    "    .gradio-container { max-width: 1200px \\!important; }\n",
    "    .header-text { text-align: center; color: #2d5aa0; margin-bottom: 20px; }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=css, title=\"ChatterBox TTS - Colab\") as demo:\n",
    "        \n",
    "        gr.HTML(\"\"\"\n",
    "        <div class=\"header-text\">\n",
    "            <h1>üéôÔ∏è ChatterBox TTS Studio</h1>\n",
    "            <p>üöÄ <strong>Google Colab Edition</strong> with GPU Acceleration</p>\n",
    "            <p>State-of-the-art Text-to-Speech ‚Ä¢ Voice Cloning ‚Ä¢ Public URL Sharing</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                gr.Markdown(\"### üìù Text Input\")\n",
    "                \n",
    "                sample_dropdown = gr.Dropdown(\n",
    "                    choices=[\"Custom\"] + [f\"{i+1}. {text[:50]}...\" for i, text in enumerate(SAMPLE_TEXTS)],\n",
    "                    value=\"Custom\",\n",
    "                    label=\"Quick Sample Texts\"\n",
    "                )\n",
    "                \n",
    "                text_input = gr.Textbox(\n",
    "                    value=\"Hello\\! Welcome to ChatterBox TTS, running on Google Colab with GPU acceleration\\!\",\n",
    "                    label=f\"Text to Synthesize (Max {MAX_TEXT_LENGTH} chars)\",\n",
    "                    placeholder=\"Enter your text here...\",\n",
    "                    lines=4\n",
    "                )\n",
    "                \n",
    "                reference_audio = gr.Audio(\n",
    "                    sources=[\"upload\", \"microphone\"],\n",
    "                    type=\"filepath\",\n",
    "                    label=\"Reference Audio (Optional) - For voice cloning\"\n",
    "                )\n",
    "                \n",
    "                gr.Markdown(\"### üéõÔ∏è Generation Settings\")\n",
    "                \n",
    "                preset_dropdown = gr.Dropdown(\n",
    "                    choices=[\"Custom\"] + list(get_preset_configs().keys()),\n",
    "                    value=\"Neutral\",\n",
    "                    label=\"Preset Configurations\"\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    exaggeration_slider = gr.Slider(\n",
    "                        0.0, 2.0, step=0.1, value=0.5,\n",
    "                        label=\"Exaggeration (Emotion)\"\n",
    "                    )\n",
    "                    cfg_weight_slider = gr.Slider(\n",
    "                        0.0, 1.0, step=0.05, value=0.5,\n",
    "                        label=\"CFG Weight (Control)\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    temperature_slider = gr.Slider(\n",
    "                        0.1, 2.0, step=0.1, value=0.8,\n",
    "                        label=\"Temperature (Variation)\"\n",
    "                    )\n",
    "                    seed_input = gr.Number(\n",
    "                        value=0,\n",
    "                        label=\"Seed (0=random)\"\n",
    "                    )\n",
    "                \n",
    "                generate_btn = gr.Button(\n",
    "                    \"üéµ Generate Speech\",\n",
    "                    variant=\"primary\",\n",
    "                    size=\"lg\"\n",
    "                )\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"### üîä Generated Audio\")\n",
    "                \n",
    "                audio_output = gr.Audio(\n",
    "                    label=\"Generated Speech\",\n",
    "                    show_download_button=True\n",
    "                )\n",
    "                \n",
    "                status_output = gr.Textbox(\n",
    "                    label=\"Generation Status\",\n",
    "                    lines=8,\n",
    "                    interactive=False\n",
    "                )\n",
    "                \n",
    "                gr.Markdown(\"### ‚ö° Quick Actions\")\n",
    "                with gr.Row():\n",
    "                    clear_btn = gr.Button(\"üóëÔ∏è Clear\", size=\"sm\")\n",
    "                    info_btn = gr.Button(\"‚ÑπÔ∏è Info\", size=\"sm\")\n",
    "        \n",
    "        # Event handlers\n",
    "        sample_dropdown.change(load_sample_text, [sample_dropdown], [text_input])\n",
    "        preset_dropdown.change(apply_preset, [preset_dropdown], [exaggeration_slider, cfg_weight_slider, temperature_slider])\n",
    "        generate_btn.click(generate_speech, [text_input, reference_audio, exaggeration_slider, cfg_weight_slider, temperature_slider, seed_input, preset_dropdown], [audio_output, status_output])\n",
    "        clear_btn.click(lambda: (None, \"\"), [], [audio_output, status_output])\n",
    "        \n",
    "        def show_info():\n",
    "            info = f\"üéôÔ∏è ChatterBox TTS - Colab Edition\\n\\n\"\n",
    "            info += f\"üñ•Ô∏è Device: {DEVICE}\\n\"\n",
    "            if model:\n",
    "                info += f\"üéµ Sample Rate: {model.sr} Hz\\n\"\n",
    "                info += f\"üéØ Model Device: {model.device}\\n\"\n",
    "            info += \"\\nüìä Available Presets:\\n\"\n",
    "            for name, config in get_preset_configs().items():\n",
    "                info += f\"‚Ä¢ {name}: exag={config['exaggeration']}, cfg={config['cfg_weight']}, temp={config['temperature']}\\n\"\n",
    "            return info\n",
    "        \n",
    "        info_btn.click(show_info, [], [status_output])\n",
    "    \n",
    "    return demo\n",
    "\n",
    "print(\"‚úÖ Gradio interface ready\\!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "launch_interface"
   },
   "source": [
    "## üöÄ Launch Gradio Interface with Public URL\n",
    "\n",
    "**üéØ This is the main cell\\!** Run this to launch the Gradio interface with a public URL.\n",
    "\n",
    "### üåê Public URL Benefits\n",
    "- **Share instantly**: Send the URL to anyone\n",
    "- **No installation**: Works on any device with a browser\n",
    "- **Collaborative**: Multiple people can use it simultaneously\n",
    "- **Secure**: HTTPS encryption and temporary URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_gradio"
   },
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "if model is not None:\n",
    "    print(\"üöÄ Launching ChatterBox TTS Gradio Interface...\")\n",
    "    print(\"üì° Creating public URL for worldwide access...\")\n",
    "    print(\"‚è≥ This may take a moment...\")\n",
    "    print()\n",
    "    \n",
    "    # Create and launch the interface\n",
    "    demo = create_gradio_interface()\n",
    "    \n",
    "    # Launch with public URL sharing\n",
    "    demo.launch(\n",
    "        share=True,           # üåê Enable public URL sharing\n",
    "        debug=False,          # Disable debug mode for cleaner output\n",
    "        show_error=True,      # Show detailed error messages\n",
    "        server_name=\"0.0.0.0\",   # Allow external connections\n",
    "        server_port=7860,     # Default port\n",
    "        enable_queue=True,    # Enable request queuing\n",
    "        max_threads=4,        # Limit concurrent requests\n",
    "        show_tips=True,       # Show helpful tips\n",
    "        quiet=False           # Show launch information\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ùå Cannot launch interface - model not loaded\\!\")\n",
    "    print(\"üí° Please run the model loading cell above first.\")\n",
    "    print(\"üîÑ If the model failed to load, try restarting the runtime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "success_info"
   },
   "source": [
    "## üéâ Success\\! Interface Launched\n",
    "\n",
    "If everything worked correctly, you should see output above with:\n",
    "\n",
    "### üîó URLs Generated\n",
    "1. **Local URL**:  (Colab internal)\n",
    "2. **üåê Public URL**:  ‚Üê **Share this one\\!**\n",
    "\n",
    "### üì§ How to Share & Test\n",
    "\n",
    "1. **üìã Copy the public URL** from the output above\n",
    "2. **üîó Share it with anyone** - they can access immediately\n",
    "3. **üì± Test on different devices** - phones, tablets, computers\n",
    "4. **üë• Collaborate in real-time** - multiple users can use it\n",
    "\n",
    "### üéØ Interface Features\n",
    "\n",
    "- **üé§ Text-to-Speech**: Type any text and generate natural speech\n",
    "- **üé≠ Voice Cloning**: Upload audio samples to clone voices\n",
    "- **üéõÔ∏è Advanced Controls**: Fine-tune emotion, stability, and variation\n",
    "- **üé≤ Presets**: Quick settings for different speech styles\n",
    "- **üìù Sample Texts**: Built-in examples for immediate testing\n",
    "- **üîä Audio Playback**: Listen and download generated speech\n",
    "- **üöÄ GPU Acceleration**: Fast generation with Colab's GPU\n",
    "\n",
    "### üí° Pro Tips\n",
    "\n",
    "- **üéØ Best Results**: Use clear, punctuated text (avoid very long sentences)\n",
    "- **üé§ Voice Cloning**: Upload 3-10 seconds of clear, single-speaker audio\n",
    "- **üéõÔ∏è Parameters**: Start with presets, then fine-tune manually\n",
    "- **‚è∞ URL Expiry**: Public URLs expire after 72 hours for security\n",
    "- **üîÑ Keep Running**: Keep this Colab tab open while others use the URL\n",
    "\n",
    "### üêõ Troubleshooting\n",
    "\n",
    "- **No URL generated**: Check if the model loaded successfully above\n",
    "- **Interface not responding**: Restart runtime and run all cells again\n",
    "- **Slow generation**: Normal on CPU, much faster with GPU enabled\n",
    "- **Audio issues**: Check browser permissions and audio settings\n",
    "\n",
    "---\n",
    "\n",
    "**üéôÔ∏è Enjoy creating amazing voices with ChatterBox TTS\\!**\n",
    "\n",
    "**üîó Share the public URL** and let others experience the power of AI voice synthesis\\!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}