{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è ChatterBox TTS - Kaggle Demo\n",
    "\n",
    "Welcome to the **ChatterBox TTS** demonstration notebook! This notebook showcases Resemble AI's state-of-the-art open-source text-to-speech model.\n",
    "\n",
    "## üåü Key Features\n",
    "- **Zero-shot TTS**: Generate speech from any text without training\n",
    "- **Voice Cloning**: Clone voices from short audio samples\n",
    "- **Emotion Control**: Adjust speech intensity and exaggeration\n",
    "- **High Quality**: Outperforms many commercial TTS systems\n",
    "- **MIT Licensed**: Free for commercial use\n",
    "\n",
    "## üìã What You'll Learn\n",
    "1. How to set up ChatterBox TTS in Kaggle\n",
    "2. Basic text-to-speech generation\n",
    "3. Advanced parameter tuning\n",
    "4. Voice cloning techniques\n",
    "5. Error handling and troubleshooting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Environment Setup\n",
    "\n",
    "First, let's install all the required dependencies. This may take a few minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ChatterBox TTS and dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package with proper error handling\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Core dependencies\n",
    "packages = [\n",
    "    \"chatterbox-tts\",\n",
    "    \"librosa\",\n",
    "    \"IPython\"\n",
    "]\n",
    "\n",
    "print(\"üöÄ Installing ChatterBox TTS and dependencies...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n‚ú® Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries & Device Detection\n",
    "\n",
    "Let's import the necessary libraries and detect the best available compute device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display, HTML, Markdown\n",
    "\n",
    "# Import ChatterBox TTS\n",
    "try:\n",
    "    from chatterbox.tts import ChatterboxTTS\n",
    "    print(\"‚úÖ ChatterBox TTS imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import ChatterBox TTS: {e}\")\n",
    "    print(\"Please ensure the installation completed successfully.\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device detection with fallback\n",
    "def detect_device():\n",
    "    \"\"\"Detect the best available device for inference\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üöÄ CUDA GPU detected: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "        print(\"üçé Apple MPS detected\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"üíª Using CPU (GPU not available)\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "device = detect_device()\n",
    "print(f\"\\nüéØ Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Load ChatterBox TTS Model\n",
    "\n",
    "Now let's load the pre-trained ChatterBox TTS model. This will download the model weights on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chatterbox_model(device):\n",
    "    \"\"\"Load ChatterBox TTS model with error handling\"\"\"\n",
    "    try:\n",
    "        print(\"üì• Loading ChatterBox TTS model...\")\n",
    "        print(\"‚è≥ This may take a few minutes on first run (downloading ~2GB of model weights)\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model = ChatterboxTTS.from_pretrained(device=device)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded successfully in {load_time:.1f} seconds!\")\n",
    "        print(f\"üéµ Sample rate: {model.sr} Hz\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load model: {e}\")\n",
    "        print(\"\\nüîß Troubleshooting tips:\")\n",
    "        print(\"1. Ensure you have internet access for model download\")\n",
    "        print(\"2. Check if you have sufficient disk space (~2GB)\")\n",
    "        print(\"3. Try restarting the kernel if you encounter memory issues\")\n",
    "        return None\n",
    "\n",
    "# Load the model\n",
    "model = load_chatterbox_model(device)\n",
    "\n",
    "if model is not None:\n",
    "    print(\"\\nüéâ ChatterBox TTS is ready to generate speech!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Model loading failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé§ Basic Text-to-Speech Generation\n",
    "\n",
    "Let's start with some basic TTS examples using the default voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speech(model, text, save_path=None, **kwargs):\n",
    "    \"\"\"Generate speech from text with timing and error handling\"\"\"\n",
    "    if model is None:\n",
    "        print(\"‚ùå Model not loaded. Please run the model loading cell first.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print(f\"üéØ Generating speech for: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        wav = model.generate(text, **kwargs)\n",
    "        generation_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate audio duration\n",
    "        audio_duration = wav.shape[-1] / model.sr\n",
    "        rtf = generation_time / audio_duration  # Real-time factor\n",
    "        \n",
    "        print(f\"‚úÖ Generated {audio_duration:.1f}s of audio in {generation_time:.1f}s (RTF: {rtf:.2f}x)\")\n",
    "        \n",
    "        # Save if path provided\n",
    "        if save_path:\n",
    "            torchaudio.save(save_path, wav, model.sr)\n",
    "            print(f\"üíæ Saved to: {save_path}\")\n",
    "        \n",
    "        return wav\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Generation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Sample texts for demonstration\n",
    "sample_texts = [\n",
    "    \"Hello! Welcome to ChatterBox TTS, the state-of-the-art open source text-to-speech system.\",\n",
    "    \"The quick brown fox jumps over the lazy dog. This pangram contains every letter of the alphabet.\",\n",
    "    \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole filled with worms and oozy smells.\"\n",
    "]\n",
    "\n",
    "# Generate speech for the first sample\n",
    "if model is not None:\n",
    "    print(\"üéµ Generating basic TTS example...\\n\")\n",
    "    \n",
    "    wav = generate_speech(model, sample_texts[0], save_path=\"basic_example.wav\")\n",
    "    \n",
    "    if wav is not None:\n",
    "        print(\"\\nüîä Click play to listen:\")\n",
    "        display(Audio(wav.squeeze().numpy(), rate=model.sr))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please load the model first before generating speech.\")
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Advanced Parameter Tuning\n",
    "\n",
    "ChatterBox TTS offers several parameters to control the generated speech quality and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_parameters(model, text):\n",
    "    \"\"\"Demonstrate different parameter settings\"\"\"\n",
    "    if model is None:\n",
    "        print(\"‚ùå Model not loaded.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üéõÔ∏è Exploring different parameter settings...\\n\")\n",
    "    \n",
    "    # Parameter configurations to test\n",
    "    configs = [\n",
    "        {\"name\": \"Default\", \"exaggeration\": 0.5, \"cfg_weight\": 0.5, \"temperature\": 0.8},\n",
    "        {\"name\": \"Calm & Controlled\", \"exaggeration\": 0.2, \"cfg_weight\": 0.7, \"temperature\": 0.6},\n",
    "        {\"name\": \"Expressive & Dynamic\", \"exaggeration\": 0.8, \"cfg_weight\": 0.3, \"temperature\": 0.9},\n",
    "        {\"name\": \"Dramatic & Intense\", \"exaggeration\": 1.0, \"cfg_weight\": 0.2, \"temperature\": 1.0}\n",
    "    ]\n",
    "    \n",
    "    for i, config in enumerate(configs):\n",
    "        print(f\"\\nüìä Configuration {i+1}: {config['name']}\")\n",
    "        print(f\"   Exaggeration: {config['exaggeration']}, CFG Weight: {config['cfg_weight']}, Temperature: {config['temperature']}\")\n",
    "        \n",
    "        wav = generate_speech(\n",
    "            model, text,\n",
    "            save_path=f\"param_demo_{i+1}.wav\",\n",
    "            exaggeration=config['exaggeration'],\n",
    "            cfg_weight=config['cfg_weight'],\n",
    "            temperature=config['temperature']\n",
    "        )\n",
    "        \n",
    "        if wav is not None:\n",
    "            print(f\"üîä {config['name']} version:\")\n",
    "            display(Audio(wav.squeeze().numpy(), rate=model.sr))\n",
    "\n",
    "# Demonstrate parameter variations\n",
    "demo_text = \"This is a demonstration of ChatterBox TTS with different parameter settings. Notice how the emotion and intensity change!\"\n",
    "\n",
    "if model is not None:\n",
    "    demonstrate_parameters(model, demo_text)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please load the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Voice Cloning with Audio Prompts\n",
    "\n",
    "One of ChatterBox's most powerful features is voice cloning using short audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_audio_prompt():\n",
    "    \"\"\"Create a sample audio prompt for voice cloning demonstration\"\"\"\n",
    "    print(\"üé§ Creating sample audio prompt...\")\n",
    "    \n",
    "    # Generate a reference audio using the default voice\n",
    "    if model is not None:\n",
    "        reference_text = \"Hello, this is a reference voice sample for cloning.\"\n",
    "        reference_wav = model.generate(reference_text)\n",
    "        \n",
    "        # Save as reference\n",
    "        torchaudio.save(\"reference_voice.wav\", reference_wav, model.sr)\n",
    "        print(\"‚úÖ Sample reference audio created: reference_voice.wav\")\n",
    "        \n",
    "        print(\"\\nüîä Reference voice:\")\n",
    "        display(Audio(reference_wav.squeeze().numpy(), rate=model.sr))\n",
    "        \n",
    "        return \"reference_voice.wav\"\n",
    "    return None\n",
    "\n",
    "def demonstrate_voice_cloning(model, reference_path, target_text):\n",
    "    \"\"\"Demonstrate voice cloning with audio prompt\"\"\"\n",
    "    if model is None or not Path(reference_path).exists():\n",
    "        print(\"‚ùå Model not loaded or reference audio not found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüé≠ Cloning voice from: {reference_path}\")\n",
    "    print(f\"üìù Target text: '{target_text}'\")\n",
    "    \n",
    "    try:\n",
    "        # Generate with voice cloning\n",
    "        cloned_wav = model.generate(\n",
    "            target_text,\n",
    "            audio_prompt_path=reference_path,\n",
    "            exaggeration=0.5\n",
    "        )\n",
    "        \n",
    "        # Save cloned audio\n",
    "        torchaudio.save(\"cloned_voice.wav\", cloned_wav, model.sr)\n",
    "        print(\"‚úÖ Voice cloning successful!\")\n",
    "        \n",
    "        print(\"\\nüîä Cloned voice speaking new text:\")\n",
    "        display(Audio(cloned_wav.squeeze().numpy(), rate=model.sr))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Voice cloning failed: {e}\")\n",
    "\n",
    "# Voice cloning demonstration\n",
    "if model is not None:\n",
    "    print(\"üé≠ Voice Cloning Demonstration\\n\")\n",
    "    \n",
    "    # Create sample reference audio\n",
    "    reference_path = create_sample_audio_prompt()\n",
    "    \n",
    "    if reference_path:\n",
    "        # Clone voice with new text\n",
    "        new_text = \"Now I'm speaking completely different words, but with the same voice characteristics!\"\n",
    "        demonstrate_voice_cloning(model, reference_path, new_text)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please load the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Interactive Text Generation\n",
    "\n",
    "Try generating speech with your own text input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_tts_generation():\n",
    "    \"\"\"Interactive TTS generation with user input\"\"\"\n",
    "    if model is None:\n",
    "        print(\"‚ùå Model not loaded. Please run the model loading cell first.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üé§ Interactive TTS Generation\")\n",
    "    print(\"Enter your text below and run the cell to generate speech!\\n\")\n",
    "    \n",
    "    # User input text (modify this to test different texts)\n",
    "    user_text = \"Welcome to the future of text-to-speech technology! ChatterBox TTS brings your words to life with incredible realism and emotion.\"\n",
    "    \n",
    "    # Customizable parameters\n",
    "    exaggeration = 0.6  # 0.0 to 1.0+ (higher = more expressive)\n",
    "    cfg_weight = 0.5    # 0.0 to 1.0 (higher = more controlled)\n",
    "    temperature = 0.8   # 0.0 to 1.0+ (higher = more varied)\n",
    "    \n",
    "    print(f\"üìù Text: '{user_text}'\")\n",
    "    print(f\"üéõÔ∏è Parameters: exaggeration={exaggeration}, cfg_weight={cfg_weight}, temperature={temperature}\")\n",
    "    \n",
    "    # Generate speech\n",
    "    wav = generate_speech(\n",
    "        model, user_text,\n",
    "        save_path=\"interactive_output.wav\",\n",
    "        exaggeration=exaggeration,\n",
    "        cfg_weight=cfg_weight,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    if wav is not None:\n",
    "        print(\"\\nüîä Generated audio:\")\n",
    "        display(Audio(wav.squeeze().numpy(), rate=model.sr))\n",
    "        \n",
    "        print(\"\\nüí° Tips for better results:\")\n",
    "        print(\"‚Ä¢ Modify the 'user_text' variable above with your own text\")\n",
    "        print(\"‚Ä¢ Adjust 'exaggeration' for more/less emotional speech\")\n",
    "        print(\"‚Ä¢ Increase 'cfg_weight' for more controlled, stable output\")\n",
    "        print(\"‚Ä¢ Adjust 'temperature' for more/less variation in speech\")\n",
    "\n",
    "# Run interactive generation\n",
    "interactive_tts_generation()""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Error Handling & Troubleshooting\n",
    "\n",
    "Common issues and their solutions when using ChatterBox TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_diagnostics():\n",
    "    \"\"\"Run system diagnostics to identify potential issues\"\"\"\n",
    "    print(\"üîç Running System Diagnostics...\\n\")\n",
    "    \n",
    "    # Check PyTorch installation\n",
    "    print(f\"üêç Python version: {sys.version.split()[0]}\")\n",
    "    print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "    print(f\"üéµ TorchAudio version: {torchaudio.__version__}\")\n",
    "    \n",
    "    # Check device availability\n",
    "    print(f\"\\nüíª Device Information:\")\n",
    "    print(f\"   Current device: {device}\")\n",
    "    print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "    \n",
    "    # Check memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        cached = torch.cuda.memory_reserved() / 1e9\n",
    "        print(f\"\\nüß† GPU Memory Usage:\")\n",
    "        print(f\"   Allocated: {allocated:.2f}GB\")\n",
    "        print(f\"   Cached: {cached:.2f}GB\")\n",
    "    \n",
    "    # Check model status\n",
    "    print(f\"\\nü§ñ Model Status:\")\n",
    "    if model is not None:\n",
    "        print(\"   ‚úÖ Model loaded successfully\")\n",
    "        print(f\"   üìä Sample rate: {model.sr} Hz\")\n",
    "        print(f\"   üéØ Device: {model.device}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Model not loaded\")\n",
    "    \n",
    "    print(\"\\nüìã Common Issues & Solutions:\")\n",
    "    print(\"\\n1. üö´ 'CUDA out of memory' error:\")\n",
    "    print(\"   ‚Ä¢ Restart kernel and try again\")\n",
    "    print(\"   ‚Ä¢ Use CPU instead: device='cpu'\")\n",
    "    print(\"   ‚Ä¢ Generate shorter text segments\")\n",
    "    \n",
    "    print(\"\\n2. üêå Slow generation on CPU:\")\n",
    "    print(\"   ‚Ä¢ This is normal - CPU inference is slower\")\n",
    "    print(\"   ‚Ä¢ Consider using GPU if available\")\n",
    "    print(\"   ‚Ä¢ Generate shorter texts for faster results\")\n",
    "    \n",
    "    print(\"\\n3. üì• Model download issues:\")\n",
    "    print(\"   ‚Ä¢ Ensure internet connectivity\")\n",
    "    print(\"   ‚Ä¢ Check available disk space (~2GB needed)\")\n",
    "    print(\"   ‚Ä¢ Try restarting the kernel\")\n",
    "    \n",
    "    print(\"\\n4. üîä Audio playback issues:\")\n",
    "    print(\"   ‚Ä¢ Check browser audio permissions\")\n",
    "    print(\"   ‚Ä¢ Download the .wav files to play locally\")\n",
    "    print(\"   ‚Ä¢ Ensure speakers/headphones are connected\")\n",
    "\n",
    "# Run diagnostics\n",
    "system_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Performance Tips & Best Practices\n",
    "\n",
    "Optimize your ChatterBox TTS usage for the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_tips():\n",
    "    \"\"\"Display performance optimization tips\"\"\"\n",
    "    print(\"üöÄ Performance Tips & Best Practices\\n\")\n",
    "    \n",
    "    print(\"‚ö° Speed Optimization:\")\n",
    "    print(\"‚Ä¢ Use GPU when available (CUDA > MPS > CPU)\")\n",
    "    print(\"‚Ä¢ Generate shorter text segments for faster processing\")\n",
    "    print(\"‚Ä¢ Batch multiple short texts instead of one long text\")\n",
    "    print(\"‚Ä¢ Lower temperature values can be faster to generate\")\n",
    "    \n",
    "    print(\"\\nüéØ Quality Optimization:\")\n",
    "    print(\"‚Ä¢ Use proper punctuation in your text\")\n",
    "    print(\"‚Ä¢ Avoid very long sentences (>100 words)\")\n",
    "    print(\"‚Ä¢ For expressive speech: lower cfg_weight + higher exaggeration\")\n",
    "    print(\"‚Ä¢ For stable speech: higher cfg_weight + lower exaggeration\")\n",
    "    \n",
    "    print(\"\\nüé§ Voice Cloning Tips:\")\n",
    "    print(\"‚Ä¢ Use clean, high-quality reference audio (16kHz+ recommended)\")\n",
    "    print(\"‚Ä¢ Reference audio should be 3-10 seconds long\")\n",
    "    print(\"‚Ä¢ Avoid background noise in reference audio\")\n",
    "    print(\"‚Ä¢ Single speaker reference works best\")\n",
    "    \n",
    "    print(\"\\nüéõÔ∏è Parameter Guidelines:\")\n",
    "    print(\"‚Ä¢ exaggeration: 0.2-0.5 (calm), 0.5-0.8 (normal), 0.8+ (dramatic)\")\n",
    "    print(\"‚Ä¢ cfg_weight: 0.3-0.5 (expressive), 0.5-0.7 (balanced), 0.7+ (controlled)\")\n",
    "    print(\"‚Ä¢ temperature: 0.6-0.8 (stable), 0.8-1.0 (varied), 1.0+ (creative)\")\n",
    "    \n",
    "    print(\"\\nüíæ Memory Management:\")\n",
    "    print(\"‚Ä¢ Clear GPU cache between generations: torch.cuda.empty_cache()\")\n",
    "    print(\"‚Ä¢ Use torch.inference_mode() for inference-only code\")\n",
    "    print(\"‚Ä¢ Delete large variables when done: del wav\")\n",
    "\n",
    "performance_tips()\n",
    "\n",
    "# Memory cleanup utility\n",
    "def cleanup_memory():\n",
    "    \"\"\"Clean up GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"üßπ GPU memory cache cleared\")\n",
    "    else:\n",
    "        print(\"üíª Running on CPU - no GPU memory to clear\")\n",
    "\n",
    "print(\"\\nüßπ Memory Cleanup:\")\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ File Management & Downloads\n",
    "\n",
    "Manage and download your generated audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def list_generated_files():\n",
    "    \"\"\"List all generated audio files\"\"\"\n",
    "    print(\"üìÅ Generated Audio Files:\\n\")\n",
    "    \n",
    "    wav_files = list(Path('.').glob('*.wav'))\n",
    "    \n",
    "    if wav_files:\n",
    "        for i, file_path in enumerate(wav_files, 1):\n",
    "            file_size = file_path.stat().st_size / 1024  # KB\n",
    "            print(f\"{i}. {file_path.name} ({file_size:.1f} KB)\")\n",
    "        \n",
    "        print(f\"\\nüìä Total files: {len(wav_files)}\")\n",
    "        total_size = sum(f.stat().st_size for f in wav_files) / 1024\n",
    "        print(f\"üì¶ Total size: {total_size:.1f} KB\")\n",
    "    else:\n",
    "        print(\"No .wav files found. Generate some audio first!\")\n",
    "    \n",
    "    return wav_files\n",
    "\n",
    "def create_download_links(files):\n",
    "    \"\"\"Create download links for generated files\"\"\"\n",
    "    if not files:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüíæ Download Instructions:\")\n",
    "    print(\"In Kaggle, you can download files by:\")\n",
    "    print(\"1. Going to the 'Output' tab on the right\")\n",
    "    print(\"2. Finding your .wav files in the file list\")\n",
    "    print(\"3. Clicking the download button next to each file\")\n",
    "    \n",
    "    print(\"\\nüìã Files ready for download:\")\n",
    "    for file_path in files:\n",
    "        print(f\"‚Ä¢ {file_path.name}\")\n",
    "\n",
    "# List and prepare downloads\n",
    "generated_files = list_generated_files()\n",
    "create_download_links(generated_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Conclusion & Next Steps\n",
    "\n",
    "Congratulations! You've successfully explored ChatterBox TTS capabilities.\n",
    "\n",
    "### üåü What You've Learned\n",
    "\n",
    "‚úÖ **Setup & Installation**: How to install and configure ChatterBox TTS in Kaggle  \n",
    "‚úÖ **Basic TTS**: Generate speech from text with default settings  \n",
    "‚úÖ **Parameter Tuning**: Control emotion, stability, and variation in speech  \n",
    "‚úÖ **Voice Cloning**: Clone voices using audio prompts  \n",
    "‚úÖ **Troubleshooting**: Handle common issues and optimize performance  \n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "1. **Experiment with Your Own Content**:\n",
    "   - Try different text styles (poetry, dialogue, technical content)\n",
    "   - Upload your own reference audio for voice cloning\n",
    "   - Test various parameter combinations\n",
    "\n",
    "2. **Integration Ideas**:\n",
    "   - Build a chatbot with voice responses\n",
    "   - Create audiobooks from text\n",
    "   - Generate voiceovers for videos\n",
    "   - Develop accessibility tools\n",
    "\n",
    "3. **Advanced Features**:\n",
    "   - Explore the voice conversion capabilities\n",
    "   - Implement batch processing for multiple texts\n",
    "   - Create custom voice libraries\n",
    "\n",
    "### üìö Resources\n",
    "\n",
    "- **GitHub Repository**: [https://github.com/resemble-ai/chatterbox](https://github.com/resemble-ai/chatterbox)\n",
    "- **Hugging Face Demo**: [https://huggingface.co/spaces/ResembleAI/Chatterbox](https://huggingface.co/spaces/ResembleAI/Chatterbox)\n",
    "- **Discord Community**: [https://discord.gg/XqS7RxUp](https://discord.gg/XqS7RxUp)\n",
    "\n",
    "### ü§ù Contributing\n",
    "\n",
    "ChatterBox TTS is open source (MIT License). Contributions are welcome!\n",
    "\n",
    "- Report bugs and request features on GitHub\n",
    "- Share your creations with the community\n",
    "- Help improve documentation and examples\n",
    "\n",
    "---\n",
    "\n",
    "**Happy voice synthesis! üé§‚ú®**\n",
    "\n",
    "*Made with ‚ô•Ô∏è by [Resemble AI](https://resemble.ai)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
