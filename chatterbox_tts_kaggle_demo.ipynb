{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è ChatterBox TTS - Kaggle Demo\n",
    "\n",
    "Welcome to the **ChatterBox TTS** demonstration notebook! This notebook showcases Resemble AI's state-of-the-art open-source text-to-speech model.\n",
    "\n",
    "## üåü Key Features\n",
    "- **Zero-shot TTS**: Generate speech from any text without training\n",
    "- **Voice Cloning**: Clone voices from short audio samples\n",
    "- **Emotion Control**: Adjust speech intensity and exaggeration\n",
    "- **High Quality**: Outperforms many commercial TTS systems\n",
    "- **MIT Licensed**: Free for commercial use\n",
    "\n",
    "## üìã What You'll Learn\n",
    "1. How to set up ChatterBox TTS in Kaggle\n",
    "2. Basic text-to-speech generation\n",
    "3. Advanced parameter tuning\n",
    "4. Voice cloning techniques\n",
    "5. Error handling and troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Environment Setup\n",
    "\n",
    "First, let's install all the required dependencies. This may take a few minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ChatterBox TTS and dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package with proper error handling\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Core dependencies\n",
    "packages = [\n",
    "    \"chatterbox-tts\",\n",
    "    \"librosa\",\n",
    "    \"IPython\"\n",
    "]\n",
    "\n",
    "print(\"üöÄ Installing ChatterBox TTS and dependencies...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n‚ú® Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries & Device Detection\n",
    "\n",
    "Let's import the necessary libraries and detect the best available compute device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Import ChatterBox TTS\n",
    "try:\n",
    "    from chatterbox.tts import ChatterboxTTS\n",
    "    print(\"‚úÖ ChatterBox TTS imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import ChatterBox TTS: {e}\")\n",
    "    print(\"Please ensure the installation completed successfully.\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device detection with fallback\n",
    "def detect_device():\n",
    "    \"\"\"Detect the best available device for inference\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üöÄ CUDA GPU detected: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "        print(\"üçé Apple MPS detected\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"üíª Using CPU (GPU not available)\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "device = detect_device()\n",
    "print(f\"\\nüéØ Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Load ChatterBox TTS Model\n",
    "\n",
    "Now let's load the pre-trained ChatterBox TTS model. This will download the model weights on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chatterbox_model(device):\n",
    "    \"\"\"Load ChatterBox TTS model with error handling\"\"\"\n",
    "    try:\n",
    "        print(\"üì• Loading ChatterBox TTS model...\")\n",
    "        print(\"‚è≥ This may take a few minutes on first run (downloading ~2GB of model weights)\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model = ChatterboxTTS.from_pretrained(device=device)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded successfully in {load_time:.1f} seconds!\")\n",
    "        print(f\"üéµ Sample rate: {model.sr} Hz\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load model: {e}\")\n",
    "        print(\"\\nüîß Troubleshooting tips:\")\n",
    "        print(\"1. Ensure you have internet access for model download\")\n",
    "        print(\"2. Check if you have sufficient disk space (~2GB)\")\n",
    "        print(\"3. Try restarting the kernel if you encounter memory issues\")\n",
    "        return None\n",
    "\n",
    "# Load the model\n",
    "model = load_chatterbox_model(device)\n",
    "\n",
    "if model is not None:\n",
    "    print(\"\\nüéâ ChatterBox TTS is ready to generate speech!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Model loading failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé§ Basic Text-to-Speech Generation\n",
    "\n",
    "Let's start with some basic TTS examples using the default voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speech(model, text, save_path=None, **kwargs):\n",
    "    \"\"\"Generate speech from text with timing and error handling\"\"\"\n",
    "    if model is None:\n",
    "        print(\"‚ùå Model not loaded. Please run the model loading cell first.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print(f\"üéØ Generating speech for: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        wav = model.generate(text, **kwargs)\n",
    "        generation_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate audio duration\n",
    "        audio_duration = wav.shape[-1] / model.sr\n",
    "        rtf = generation_time / audio_duration  # Real-time factor\n",
    "        \n",
    "        print(f\"‚úÖ Generated {audio_duration:.1f}s of audio in {generation_time:.1f}s (RTF: {rtf:.2f}x)\")\n",
    "        \n",
    "        # Save if path provided\n",
    "        if save_path:\n",
    "            torchaudio.save(save_path, wav, model.sr)\n",
    "            print(f\"üíæ Saved to: {save_path}\")\n",
    "        \n",
    "        return wav\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Generation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Sample texts for demonstration\n",
    "sample_texts = [\n",
    "    \"Hello! Welcome to ChatterBox TTS, the state-of-the-art open source text-to-speech system.\",\n",
    "    \"The quick brown fox jumps over the lazy dog. This pangram contains every letter of the alphabet.\",\n",
    "    \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole filled with worms and oozy smells.\"\n",
    "]\n",
    "\n",
    "# Generate speech for the first sample\n",
    "if model is not None:\n",
    "    print(\"üéµ Generating basic TTS example...\\n\")\n",
    "    \n",
    "    wav = generate_speech(model, sample_texts[0], save_path=\"basic_example.wav\")\n",
    "    \n",
    "    if wav is not None:\n",
    "        print(\"\\nüîä Click play to listen:\")\n",
    "        display(Audio(wav.squeeze().numpy(), rate=model.sr))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please load the model first before generating speech.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Advanced Parameter Tuning",
    "",
    "ChatterBox TTS offers several parameters to control the generated speech quality and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_parameters(model, text):",
    "    \"\"\"Demonstrate different parameter settings\"\"\"",
    "    if model is None:",
    "        print(\"‚ùå Model not loaded.\")",
    "        return",
    "    ",
    "    print(\"üéõÔ∏è Exploring different parameter settings...\\n\")",
    "    ",
    "    # Parameter configurations to test",
    "    configs = [",
    "        {\"name\": \"Default\", \"exaggeration\": 0.5, \"cfg_weight\": 0.5, \"temperature\": 0.8},",
    "        {\"name\": \"Calm & Controlled\", \"exaggeration\": 0.2, \"cfg_weight\": 0.7, \"temperature\": 0.6},",
    "        {\"name\": \"Expressive & Dynamic\", \"exaggeration\": 0.8, \"cfg_weight\": 0.3, \"temperature\": 0.9},",
    "        {\"name\": \"Dramatic & Intense\", \"exaggeration\": 1.0, \"cfg_weight\": 0.2, \"temperature\": 1.0}",
    "    ]",
    "    ",
    "    for i, config in enumerate(configs):",
    "        print(f\"\\nüìä Configuration {i+1}: {config['name']}\")",
    "        print(f\"   Exaggeration: {config['exaggeration']}, CFG Weight: {config['cfg_weight']}, Temperature: {config['temperature']}\")",
    "        ",
    "        wav = generate_speech(",
    "            model, text,",
    "            save_path=f\"param_demo_{i+1}.wav\",",
    "            exaggeration=config['exaggeration'],",
    "            cfg_weight=config['cfg_weight'],",
    "            temperature=config['temperature']",
    "        )",
    "        ",
    "        if wav is not None:",
    "            print(f\"üîä {config['name']} version:\")",
    "            display(Audio(wav.squeeze().numpy(), rate=model.sr))",
    "",
    "# Demonstrate parameter variations",
    "demo_text = \"This is a demonstration of ChatterBox TTS with different parameter settings. Notice how the emotion and intensity change!\"",
    "",
    "if model is not None:",
    "    demonstrate_parameters(model, demo_text)",
    "else:",
    "    print(\"‚ö†Ô∏è Please load the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Voice Cloning with Audio Prompts",
    "",
    "One of ChatterBox's most powerful features is voice cloning using short audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_audio_prompt():",
    "    \"\"\"Create a sample audio prompt for voice cloning demonstration\"\"\"",
    "    print(\"üé§ Creating sample audio prompt...\")",
    "    ",
    "    # Generate a reference audio using the default voice",
    "    if model is not None:",
    "        reference_text = \"Hello, this is a reference voice sample for cloning.\"",
    "        reference_wav = model.generate(reference_text)",
    "        ",
    "        # Save as reference",
    "        torchaudio.save(\"reference_voice.wav\", reference_wav, model.sr)",
    "        print(\"‚úÖ Sample reference audio created: reference_voice.wav\")",
    "        ",
    "        print(\"\\nüîä Reference voice:\")",
    "        display(Audio(reference_wav.squeeze().numpy(), rate=model.sr))",
    "        ",
    "        return \"reference_voice.wav\"",
    "    return None",
    "",
    "def demonstrate_voice_cloning(model, reference_path, target_text):",
    "    \"\"\"Demonstrate voice cloning with audio prompt\"\"\"",
    "    if model is None or not Path(reference_path).exists():",
    "        print(\"‚ùå Model not loaded or reference audio not found.\")",
    "        return",
    "    ",
    "    print(f\"\\nüé≠ Cloning voice from: {reference_path}\")",
    "    print(f\"üìù Target text: '{target_text}'\")",
    "    ",
    "    try:",
    "        # Generate with voice cloning",
    "        cloned_wav = model.generate(",
    "            target_text,",
    "            audio_prompt_path=reference_path,",
    "            exaggeration=0.5",
    "        )",
    "        ",
    "        # Save cloned audio",
    "        torchaudio.save(\"cloned_voice.wav\", cloned_wav, model.sr)",
    "        print(\"‚úÖ Voice cloning successful!\")",
    "        ",
    "        print(\"\\nüîä Cloned voice speaking new text:\")",
    "        display(Audio(cloned_wav.squeeze().numpy(), rate=model.sr))",
    "        ",
    "    except Exception as e:",
    "        print(f\"‚ùå Voice cloning failed: {e}\")",
    "",
    "# Voice cloning demonstration",
    "if model is not None:",
    "    print(\"üé≠ Voice Cloning Demonstration\\n\")",
    "    ",
    "    # Create sample reference audio",
    "    reference_path = create_sample_audio_prompt()",
    "    ",
    "    if reference_path:",
    "        # Clone voice with new text",
    "        new_text = \"Now I'm speaking completely different words, but with the same voice characteristics!\"",
    "        demonstrate_voice_cloning(model, reference_path, new_text)",
    "else:",
    "    print(\"‚ö†Ô∏è Please load the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Interactive Text Generation",
    "",
    "Try generating speech with your own text input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_tts_generation():",
    "    \"\"\"Interactive TTS generation with user input\"\"\"",
    "    if model is None:",
    "        print(\"‚ùå Model not loaded. Please run the model loading cell first.\")",
    "        return",
    "    ",
    "    print(\"üé§ Interactive TTS Generation\")",
    "    print(\"Enter your text below and run the cell to generate speech!\\n\")",
    "    ",
    "    # User input text (modify this to test different texts)",
    "    user_text = \"Welcome to the future of text-to-speech technology! ChatterBox TTS brings your words to life with incredible realism and emotion.\"",
    "    ",
    "    # Customizable parameters",
    "    exaggeration = 0.6  # 0.0 to 1.0+ (higher = more expressive)",
    "    cfg_weight = 0.5    # 0.0 to 1.0 (higher = more controlled)",
    "    temperature = 0.8   # 0.0 to 1.0+ (higher = more varied)",
    "    ",
    "    print(f\"üìù Text: '{user_text}'\")",
    "    print(f\"üéõÔ∏è Parameters: exaggeration={exaggeration}, cfg_weight={cfg_weight}, temperature={temperature}\")",
    "    ",
    "    # Generate speech",
    "    wav = generate_speech(",
    "        model, user_text,",
    "        save_path=\"interactive_output.wav\",",
    "        exaggeration=exaggeration,",
    "        cfg_weight=cfg_weight,",
    "        temperature=temperature",
    "    )",
    "    ",
    "    if wav is not None:",
    "        print(\"\\nüîä Generated audio:\")",
    "        display(Audio(wav.squeeze().numpy(), rate=model.sr))",
    "        ",
    "        print(\"\\nüí° Tips for better results:\")",
    "        print(\"‚Ä¢ Modify the 'user_text' variable above with your own text\")",
    "        print(\"‚Ä¢ Adjust 'exaggeration' for more/less emotional speech\")",
    "        print(\"‚Ä¢ Increase 'cfg_weight' for more controlled, stable output\")",
    "        print(\"‚Ä¢ Adjust 'temperature' for more/less variation in speech\")",
    "",
    "# Run interactive generation",
    "interactive_tts_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß System Diagnostics & Troubleshooting",
    "",
    "Check your system status and get help with common issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_diagnostics():",
    "    \"\"\"Run system diagnostics to identify potential issues\"\"\"",
    "    print(\"üîç Running System Diagnostics...\\n\")",
    "    ",
    "    # Check PyTorch installation",
    "    print(f\"üêç Python version: {sys.version.split()[0]}\")",
    "    print(f\"üî• PyTorch version: {torch.__version__}\")",
    "    print(f\"üéµ TorchAudio version: {torchaudio.__version__}\")",
    "    ",
    "    # Check device availability",
    "    print(f\"\\nüíª Device Information:\")",
    "    print(f\"   Current device: {device}\")",
    "    print(f\"   CUDA available: {torch.cuda.is_available()}\")",
    "    if torch.cuda.is_available():",
    "        print(f\"   CUDA version: {torch.version.cuda}\")",
    "        print(f\"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")",
    "    ",
    "    # Check model status",
    "    print(f\"\\nü§ñ Model Status:\")",
    "    if model is not None:",
    "        print(\"   ‚úÖ Model loaded successfully\")",
    "        print(f\"   üìä Sample rate: {model.sr} Hz\")",
    "        print(f\"   üéØ Device: {model.device}\")",
    "    else:",
    "        print(\"   ‚ùå Model not loaded\")",
    "    ",
    "    print(\"\\nüìã Common Issues & Solutions:\")",
    "    print(\"\\n1. üö´ 'CUDA out of memory' error:\")",
    "    print(\"   ‚Ä¢ Restart kernel and try again\")",
    "    print(\"   ‚Ä¢ Use CPU instead: device='cpu'\")",
    "    print(\"   ‚Ä¢ Generate shorter text segments\")",
    "    ",
    "    print(\"\\n2. üêå Slow generation on CPU:\")",
    "    print(\"   ‚Ä¢ This is normal - CPU inference is slower\")",
    "    print(\"   ‚Ä¢ Consider using GPU if available\")",
    "    print(\"   ‚Ä¢ Generate shorter texts for faster results\")",
    "",
    "# Run diagnostics",
    "system_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ File Management",
    "",
    "List and manage your generated audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os",
    "from pathlib import Path",
    "",
    "def list_generated_files():",
    "    \"\"\"List all generated audio files\"\"\"",
    "    print(\"üìÅ Generated Audio Files:\\n\")",
    "    ",
    "    wav_files = list(Path('.').glob('*.wav'))",
    "    ",
    "    if wav_files:",
    "        for i, file_path in enumerate(wav_files, 1):",
    "            file_size = file_path.stat().st_size / 1024  # KB",
    "            print(f\"{i}. {file_path.name} ({file_size:.1f} KB)\")",
    "        ",
    "        print(f\"\\nüìä Total files: {len(wav_files)}\")",
    "        total_size = sum(f.stat().st_size for f in wav_files) / 1024",
    "        print(f\"üì¶ Total size: {total_size:.1f} KB\")",
    "        ",
    "        print(\"\\nüíæ Download Instructions:\")",
    "        print(\"In Kaggle, you can download files by:\")",
    "        print(\"1. Going to the 'Output' tab on the right\")",
    "        print(\"2. Finding your .wav files in the file list\")",
    "        print(\"3. Clicking the download button next to each file\")",
    "    else:",
    "        print(\"No .wav files found. Generate some audio first!\")",
    "    ",
    "    return wav_files",
    "",
    "# List generated files",
    "generated_files = list_generated_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Conclusion & Next Steps",
    "",
    "Congratulations! You've successfully explored ChatterBox TTS capabilities.",
    "",
    "### üåü What You've Learned",
    "",
    "‚úÖ **Setup & Installation**: How to install and configure ChatterBox TTS in Kaggle  ",
    "‚úÖ **Basic TTS**: Generate speech from text with default settings  ",
    "‚úÖ **Parameter Tuning**: Control emotion, stability, and variation in speech  ",
    "‚úÖ **Voice Cloning**: Clone voices using audio prompts  ",
    "‚úÖ **Troubleshooting**: Handle common issues and optimize performance  ",
    "",
    "### üöÄ Next Steps",
    "",
    "1. **Experiment with Your Own Content**:",
    "   - Try different text styles (poetry, dialogue, technical content)",
    "   - Upload your own reference audio for voice cloning",
    "   - Test various parameter combinations",
    "",
    "2. **Integration Ideas**:",
    "   - Build a chatbot with voice responses",
    "   - Create audiobooks from text",
    "   - Generate voiceovers for videos",
    "   - Develop accessibility tools",
    "",
    "### üìö Resources",
    "",
    "- **GitHub Repository**: [https://github.com/resemble-ai/chatterbox](https://github.com/resemble-ai/chatterbox)",
    "- **Hugging Face Demo**: [https://huggingface.co/spaces/ResembleAI/Chatterbox](https://huggingface.co/spaces/ResembleAI/Chatterbox)",
    "- **Discord Community**: [https://discord.gg/XqS7RxUp](https://discord.gg/XqS7RxUp)",
    "",
    "---",
    "",
    "**Happy voice synthesis! üé§‚ú®**",
    "",
    "*Made with ‚ô•Ô∏è by [Resemble AI](https://resemble.ai)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
